{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring GPX files\n",
    "\n",
    "<https://ocefpaf.github.io/python4oceanographers/blog/2014/08/18/gpx/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext skip_kernel_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the qreat circle distance between two points\n",
    "    on the earth (specifiecd in decimal degrees)\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat1 - lat2\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt())\n",
    "    \n",
    "    # Radius of Earth in Kilometers is 6361\n",
    "    km = 6371 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import gpxpy\n",
    "from pandas import DataFrame\n",
    "\n",
    "def load_run_data(gpx_path, filter=\"\"):\n",
    "    path = os.path.join(gpx_path, \"**/*\" + filter + \".gpx\")\n",
    "    gpx_files = glob(path, recursive=True)\n",
    "    \n",
    "    print(\"Files ({0}): -\".format(len(gpx_files)))    \n",
    "    run_data = []\n",
    "    for file_idx, gpx_file in enumerate(gpx_files):\n",
    "        print(\"  {0}\".format(gpx_file))\n",
    "        gpx = gpxpy.parse(open(gpx_file, 'r'))\n",
    "        # Loop through tracks\n",
    "        for track_idx, track in enumerate(gpx.tracks):\n",
    "            track_name = track.name\n",
    "            track_time = track.get_time_bounds().start_time\n",
    "            track_length = track.length_3d()\n",
    "            track_duration = track.get_duration()\n",
    "            track_speed = track.get_moving_data().max_speed\n",
    "            \n",
    "            for seg_idx, segment in enumerate(track.segments):\n",
    "                segment_length = segment.length_3d()\n",
    "                for point_idx, point in enumerate(segment.points):\n",
    "                    run_data.append([file_idx, os.path.basename(gpx_file), track_idx, track_name, \n",
    "                                     track_time, track_length, track_duration, track_speed, \n",
    "                                     seg_idx, segment_length, point.time, point.latitude, \n",
    "                                     point.longitude, point.elevation, segment.get_speed(point_idx)])\n",
    "    return run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "data = load_run_data(gpx_path='./_Data/GPX/', filter='TimeFormatted')\n",
    "df = DataFrame(data, columns=['File_Index', 'File_Name', 'Index', 'Name',\n",
    "                              'Time', 'Length', 'Duration', 'Max_Speed',\n",
    "                              'Segment_Index', 'Segment_Length', 'Point_Time', 'Point_Latitude',\n",
    "                              'Point_Longitude', 'Point_Elevation', 'Point_Speed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data can be loaded twice. Once from Current and again from Archived files.\n",
    "\n",
    "# if \"File_Index\" in df:\n",
    "#     df = df.drop('File_Index', axis=1)\n",
    "\n",
    "# if \"File_Name\" in df:\n",
    "#     df = df.drop('File_Name', axis=1)\n",
    "\n",
    "# if \"Index\" in df:\n",
    "#     df = df.drop('Index', axis=1)\n",
    "\n",
    "# if \"Name\" in df:\n",
    "#     df = df.drop('Name', axis=1)\n",
    "\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# df = df.loc[df.shift() == df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(df.head().to_html(max_cols=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Time', 'Length', 'Duration', 'Max_Speed']\n",
    "tracks = df[cols].copy()\n",
    "tracks['Length'] /= 1e3\n",
    "tracks.drop_duplicates(inplace=True)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['Year'] = tracks['Time'].apply(lambda x: x.year)\n",
    "tracks['Month'] = tracks['Time'].apply(lambda x: x.month)\n",
    "tracks_grouped_month = tracks.groupby(['Year','Month'])\n",
    "tracks_grouped_month.describe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figsize=(7, 3.5)\n",
    "\n",
    "tracks_grouped_month = tracks.groupby(['Year', 'Month'])\n",
    "ax = tracks_grouped_month['Length'].sum().plot(kind='bar', figsize=figsize)\n",
    "xlabels = [text.get_text() for text in  ax.get_xticklabels()]\n",
    "ax.set_xticklabels(xlabels, rotation=70)\n",
    "_ = ax.set_ylabel('Distance (km)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figsize=(7, 3.5)\n",
    "\n",
    "tracks['Day'] = tracks['Time'].apply(lambda x: x.day)\n",
    "tracks_grouped_days = tracks.groupby(['Year', 'Month', 'Day'])\n",
    "ax = tracks_grouped_days['Length'].sum().plot(kind='bar', figsize=figsize)\n",
    "xlabels = [text.get_text() for text in  ax.get_xticklabels()]\n",
    "ax.set_xticklabels(xlabels, rotation=70)\n",
    "_ = ax.set_ylabel('Distance (km)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "d = datetime(2017,12,16)\n",
    "\n",
    "munich_hols = df[df['Time'] > d]\n",
    "munich_hols = munich_hols.dropna()\n",
    "\n",
    "# munich_hols.head()\n",
    "munich_hols.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = df.set_index(pd.DatetimeIndex(df['Point_Time']))\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "# del df['Time']\n",
    "\n",
    "import mplleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "if \"File_Index\" in df:\n",
    "    dfg = df.groupby(['File_Index', df.index.day, 'Segment_Index', 'Index'])\n",
    "else:\n",
    "    dfg = df.groupby([df.index.day, df.index.hour, 'Segment_Index'])\n",
    "    \n",
    "# dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if \"File_Index\" in df:\n",
    "    DFList = [group[1] for group in dfg]\n",
    "    for d in DFList:\n",
    "        d.to_csv(\"_OUTPUT/data_{0}.csv\".format(d['File_Index'][0]))\n",
    "        ax.plot(d['Point_Longitude'], d['Point_Latitude'], linestyle='-', linewidth=10, alpha=0.75)\n",
    "else:\n",
    "    DFList = [group[1] for group in df.groupby(df.index.day)]\n",
    "    for d in DFList:\n",
    "        ax.plot(d['Point_Longitude'], d['Point_Latitude'], linestyle='-', linewidth=10, alpha=0.75)\n",
    "\n",
    "mplleaflet.show(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = '_OUTPUT'\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "df.to_csv('_OUTPUT/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distances on surface of ellipsoid\n",
    "from vincenty import vincenty\n",
    "\n",
    "if \"File_Index\" in df:\n",
    "    for d in DFList:\n",
    "        d['lastLat'] = d['Point_Latitude'].shift(1)\n",
    "        d['lastLong'] = d['Point_Longitude'].shift(1)\n",
    "        d['dist(meters)'] = d.apply(lambda x: vincenty((x['Point_Latitude'], x['Point_Longitude']), (x['lastLat'], x['lastLong'])), axis = 1) * 1000.\n",
    "\n",
    "        print('Total distance as summed between points in track: ' + str(sum(d['dist(meters)'][1:])*0.000621371) + ' mi')\n",
    "        # The df['dist'][1:] above is because the \"shift\" sets the first lastLon,lastLat as NaN.\n",
    "        # print('Comparing to total distance contained in track.name: ' + track.name)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%skip True\n",
    "\n",
    "import folium\n",
    "\n",
    "OUTPUT_PATH = '_OUTPUT/fol/'\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "i = 0\n",
    "for d in DFList:\n",
    "    mymap = folium.Map( location=[ d.Point_Latitude.mean(), d.Point_Longitude.mean() ], zoom_start=14)\n",
    "\n",
    "    for coord in d[['Point_Latitude','Point_Longitude']].values:\n",
    "        folium.CircleMarker(location=[coord[0],coord[1]], radius=1,color='red').add_to(mymap)\n",
    "\n",
    "    i += 1\n",
    "    mymap.save(os.path.join('_OUTPUT/fol', \"fol_{0}.html\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://benalexkeen.com/resampling-time-series-data-with-pandas/\n",
    "\n",
    "weekly_summary = pd.DataFrame()\n",
    "weekly_summary['speed'] = df.Max_Speed.resample('W').mean()\n",
    "weekly_summary['duration'] = df.Duration.resample('W').sum()\n",
    "\n",
    "weekly_summary = weekly_summary.dropna(subset=['speed', 'duration'])\n",
    "\n",
    "weekly_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary = pd.DataFrame()\n",
    "daily_summary['speed'] = df.Max_Speed.resample('D').mean()\n",
    "daily_summary['duration'] = df.Duration.resample('D').sum()\n",
    "daily_summary['length'] = df.Length.resample('D').sum()\n",
    "\n",
    "daily_summary = daily_summary.dropna(subset=['speed', 'duration', 'length'])\n",
    "\n",
    "daily_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seawater as sw\n",
    "from datetime import datetime\n",
    "\n",
    "d1 = datetime(2018,3,29)\n",
    "d2 = datetime(2018,3,30)\n",
    "\n",
    "# ne66_hols = df[df['Point_Time'] >= d1]\n",
    "\n",
    "# mask = (df['Point_Time'] > d1) & (df['Point_Time'] < d2)\n",
    "# mask = (df['File_Index'] == 1) & (df['Point_Time'] > d1) & (df['Point_Time'] < d2)\n",
    "mask = (df['Point_Time'] > d1) & (df['Point_Time'] < d2)\n",
    "ne66_hols = df.loc[mask]\n",
    "\n",
    "if 'File_Index' in ne66_hols:\n",
    "    ne66_hols = ne66_hols.drop('File_Index', axis=1)\n",
    "\n",
    "if 'File_Name' in ne66_hols:\n",
    "    ne66_hols = ne66_hols.drop('File_Name', axis=1)\n",
    "\n",
    "if 'Index' in ne66_hols:\n",
    "    ne66_hols = ne66_hols.drop('Index', axis=1)\n",
    "\n",
    "ne66_hols_nodups = ne66_hols.drop_duplicates()\n",
    "\n",
    "dist, angles = sw.dist(ne66_hols_nodups['Point_Latitude'], ne66_hols_nodups['Point_Longitude'])\n",
    "\n",
    "conversion_factor =  0.62137119223733\n",
    "\n",
    "hols_dist_kms = dist.sum()\n",
    "hols_dist_miles = hols_dist_kms * conversion_factor\n",
    "\n",
    "ne66_hols_nodups.head()\n",
    "\n",
    "print(f\"{hols_dist_kms} km\")\n",
    "print(f\"{hols_dist_miles} miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
